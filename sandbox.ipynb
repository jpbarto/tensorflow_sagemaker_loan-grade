{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/jamesandersen/aws-machine-learning-demo/master/keras-deeplearning/train-model/lc-2015-loans.zip -o lc_data.zip\n",
    "!unzip lc_data.zip\n",
    "!mv lc-2015-loans.csv train_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.estimator.export.export import build_raw_serving_input_receiver_fn\n",
    "from tensorflow.python.estimator.export.export_output import PredictOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = None # dict containing 'features' and 'labels' which store ndarrays\n",
    "eval_data = None\n",
    "\n",
    "# columns to extract from the CSV\n",
    "APPLICANT_NUMERIC = ['annual_inc', 'dti', 'age_earliest_cr', 'loan_amnt', 'installment']\n",
    "APPLICANT_CATEGORICAL = ['application_type', 'home_ownership', 'addr_state', 'term']\n",
    "CREDIT_NUMERIC = ['acc_now_delinq', 'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy',\n",
    "                  'bc_util', 'delinq_2yrs', 'delinq_amnt', 'fico_range_high', 'fico_range_low',\n",
    "                  'last_fico_range_high', 'last_fico_range_low', 'open_acc', 'pub_rec', 'revol_util',\n",
    "                  'revol_bal', 'tot_coll_amt', 'tot_cur_bal', 'total_acc', 'total_rev_hi_lim',\n",
    "                  'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats',\n",
    "                  'num_bc_tl', 'num_il_tl', 'num_rev_tl_bal_gt_0', 'pct_tl_nvr_dlq',\n",
    "                  'percent_bc_gt_75', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
    "                  'total_il_high_credit_limit', 'all_util', 'loan_to_income',\n",
    "                  'installment_pct_inc', 'il_util', 'il_util_ex_mort', 'total_bal_il', 'total_cu_tl']\n",
    "\n",
    "FEATURES = APPLICANT_NUMERIC + APPLICANT_CATEGORICAL + CREDIT_NUMERIC\n",
    "LABEL = 'grade'\n",
    "COLUMNS = FEATURES + [LABEL]\n",
    "\n",
    "INPUT_TENSOR_NAME = \"inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model definition for Tensorflow Estimator.  Creates a model, defines a loss function, and produces an EstimatorSpec\n",
    "# for training by TensorFlow\n",
    "def model_fn(features, labels, mode, params = {}):\n",
    "    print (\"Creating EstimatorSpec...\")\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    if 'learning_rate' in params:\n",
    "        learning_rate = params['learning_rate']\n",
    "        \n",
    "    print ('Generating layers with input {}...'.format (features[INPUT_TENSOR_NAME]))\n",
    "    print ('Using a learning rate of {}'.format (learning_rate))\n",
    "    \n",
    "    layer1 = tf.layers.dense(features[INPUT_TENSOR_NAME], 100, activation=tf.nn.relu, kernel_constraint = tf.keras.constraints.max_norm (3))\n",
    "    layer2 = tf.layers.dropout (layer1, rate = 0.2)\n",
    "    layer3 = tf.layers.dense (layer2, 60, activation = tf.nn.relu, kernel_constraint = tf.keras.constraints.max_norm (3))\n",
    "    layer4 = tf.layers.dropout (layer3, rate = 0.2)\n",
    "    logits = tf.layers.dense (inputs = layer4, units = 7)\n",
    "    \n",
    "    print (\"Output layer: {}\".format (logits))\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input = logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    print (\"Labels data type: {}\".format (labels))\n",
    "    print (\"Predictions: {}\".format (predictions))\n",
    "    \n",
    "    # Provide an estimator spec for `ModeKeys.PREDICT`.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        print ('Returning prediction EstimatorSpec')\n",
    "        print (\"Prediction classes are {}\".format (predictions['classes']))\n",
    "        print (\"Prediction probs are {}\".format (predictions['probabilities']))\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions = predictions,\n",
    "            export_outputs={\"grade_prediction\": PredictOutput(predictions)})\n",
    "    \n",
    "    # 2. Define the loss function for training/evaluation using Tensorflow.\n",
    "    m_labels = labels\n",
    "    m_predictions = predictions\n",
    "    \n",
    "    print ('Generate loss function...')\n",
    "    # onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=7)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels = tf.cast (labels, tf.int32), \n",
    "        logits=logits\n",
    "    )\n",
    "    \n",
    "    print ('Test for train mode...')\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step()\n",
    "        )\n",
    "        \n",
    "        print (\"Returning EstimatorSpec for TRAIN mode\")\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, \n",
    "            loss=loss, \n",
    "            train_op=train_op\n",
    "        )\n",
    "    \n",
    "    print ('Generate evaluation metrics...')\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels = tf.argmax (input = labels, axis = 1), \n",
    "            predictions=predictions[\"classes\"]\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    print (\"Returning EstimatorSpec\")\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, \n",
    "        loss=loss, \n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for training data epochs should be None and shuffle_flag set to True\n",
    "# for evaluation or prediction data epochs should be 1 and shuffle_flag set to False\n",
    "def gen_input_fn(data, epochs = 1, shuffle_flag = False):   \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "            x = {INPUT_TENSOR_NAME: data['features']},\n",
    "            y = data['labels'],\n",
    "            num_epochs = epochs,\n",
    "            shuffle = shuffle_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the data CSV and return Pandas DataFrames for training / evaluation / and prediction in an 60 / 20 / 20 split\n",
    "def read_csv_data (training_dir): \n",
    "    global train_data, eval_data\n",
    "    \n",
    "    grade_categories = [g for g in \"ABCDEFG\"]\n",
    "    \n",
    "    print (\"Reading training data from {}\".format (os.path.join (training_dir, 'train_data.csv')))\n",
    "    \n",
    "    lg_data = pd.read_csv (os.path.join (training_dir, 'train_data.csv'), usecols = COLUMNS)\n",
    "    lg_data['grade'] = lg_data['grade'].astype ('category', categories = grade_categories, ordered = True)\n",
    "    # shuffle the data set\n",
    "    lg_data = lg_data.sample (frac = 1, random_state = 2501)\n",
    "    \n",
    "    bad_rows = lg_data.isnull ().T.any ().T.sum ()\n",
    "    if bad_rows > 0:\n",
    "        print(\"Rows with null/NaN values: {}\".format(bad_rows))\n",
    "        print(\"Columns with null/NaN values:\")\n",
    "        print(pd.isnull(lg_data).sum() > 0)\n",
    "        print(\"Dropping bad rows...\")\n",
    "        lg_data.dropna(axis=0, how='any', inplace=True)\n",
    "        print(\"Rows with null/NaN values: {}\".format(lg_data.isnull().T.any().T.sum()))\n",
    "        \n",
    "    # Subset to get feature data\n",
    "    x_df = lg_data.loc[:, APPLICANT_NUMERIC + CREDIT_NUMERIC + APPLICANT_CATEGORICAL]\n",
    "\n",
    "    # Update our X dataframe with categorical values replaced by one-hot encoded values\n",
    "    for col in APPLICANT_CATEGORICAL:\n",
    "        # use get_dummies() to do one hot encoding of categorical column\n",
    "        x_df = x_df.merge(pd.get_dummies(x_df[col]), left_index=True, right_index=True)\n",
    "        \n",
    "        # drop the original categorical column\n",
    "        x_df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    # Ensure all numeric features are on the same scale\n",
    "    for col in APPLICANT_NUMERIC + CREDIT_NUMERIC:\n",
    "        x_df[col] = (x_df[col] - x_df[col].mean()) / x_df[col].std()\n",
    "    x_df = x_df.astype (np.float32)\n",
    "\n",
    "    # Specify the target labels and flatten the array\n",
    "    y = pd.get_dummies(lg_data[LABEL]).astype (np.float32)\n",
    "\n",
    "    # Create train, eval, and test sets\n",
    "    eval_start = int(x_df.shape[0]*.8)\n",
    "    \n",
    "    train_data = {\n",
    "        'features': x_df.iloc[:eval_start, :].as_matrix (),\n",
    "        'labels': y.iloc[:eval_start, :].as_matrix ()\n",
    "    }\n",
    "    eval_data = {\n",
    "        'features': x_df.iloc[eval_start:, :].as_matrix (),\n",
    "        'labels': y.iloc[eval_start:, :].as_matrix ()\n",
    "    }\n",
    "    print (\"Training data set feature shape {}, label shape {}, read complete\".format (train_data['features'].shape, train_data['labels'].shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv_data ('.')\n",
    "print (\"Training data shape: {}\".format (train_data['features'].shape))\n",
    "print (\"Eval data shape: {}\".format (eval_data['features'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Estimator and prepare to train it\n",
    "model_params = {'learning_rate': 0.001}\n",
    "estimator = tf.estimator.Estimator (model_fn = model_fn, params = model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model, accuracy will be very low until 100k+ training steps\n",
    "estimator.train (input_fn = gen_input_fn (train_data, epochs = None, shuffle_flag = True), steps = 250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the effectiveness of the training using the evaluation data\n",
    "estimator.evaluate (input_fn = gen_input_fn (eval_data, epochs = 1, shuffle_flag = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the prediction data set to further evaluate the model\n",
    "pred = estimator.predict (input_fn = gen_input_fn (eval_data, epochs = 1, shuffle_flag = False))\n",
    "predictions = [p for p in pred]\n",
    "pred_classes = [p['classes'] for p in predictions]\n",
    "pred_probs = [p['probabilities'] for p in predictions]\n",
    "\n",
    "print (\"Predictions len: {}\".format (len(pred_classes)))\n",
    "print (\"Probabilities shape: {}\".format (pd.DataFrame (pred_probs).shape))\n",
    "print (predictions[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"labels type: {}\".format (type(eval_data['labels'])))\n",
    "print (pred_classes[0:3])\n",
    "print (\"Length: {}\".format (len (pred_classes)))\n",
    "print (\"-----\")\n",
    "label_classes = eval_data['labels'].argmax (1).tolist ()\n",
    "print (label_classes[0:3])\n",
    "print (\"Length: {}\".format (len(label_classes)))\n",
    "\n",
    "num_right = 0\n",
    "num_wrong = 0\n",
    "for i in range (len(pred_classes)):\n",
    "    if pred_classes[i] == label_classes[i]:\n",
    "        num_right += 1\n",
    "    else:\n",
    "        num_wrong += 1\n",
    "\n",
    "print (\"Right {}, Wrong {}, Accuracy: {}\".format (num_right, num_wrong, float(num_right) / (num_right + num_wrong)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score (label_classes, pred_classes)\n",
    "cf_matrix = confusion_matrix (label_classes, pred_classes)\n",
    "\n",
    "plt.imshow (cf_matrix, interpolation = 'nearest', cmap = plt.cm.Oranges)\n",
    "plt.title ('Endpoint Confusion Matrix')\n",
    "plt.colorbar ()\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "tick_marks = np.arange (len (classes))\n",
    "plt.yticks (tick_marks, classes)\n",
    "plt.xticks (tick_marks, classes)\n",
    "plt.ylabel ('True label')\n",
    "plt.xlabel ('Predicted label')\n",
    "\n",
    "thresh = cf_matrix.max() / 2.\n",
    "for i, j in itertools.product(range(cf_matrix.shape[0]), range(cf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(cf_matrix[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show ()\n",
    "print (\"Overall accuracy over {} samples: {}\".format (len(pred_classes), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
